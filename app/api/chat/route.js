export const runtime = 'nodejs'; // Edge Runtime (ìŠ¤íŠ¸ë¦¬ë°ìš©)

import OpenAI from "openai";
import fs from "fs";
import path from "path";

// OpenAI ì´ˆê¸°í™”
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ----- Feldman ê¸°ë³¸ ì•ˆë‚´ í”„ë¡¬í”„íŠ¸ -----
const systemPrompt = `
You are a helpful museum docent guiding users through Edmund Feldman's 4-step art critique.
Steps:
1) Description (ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?)
2) Analysis (êµ¬ì„±/ëŒ€ë¹„/ê· í˜• ê´€ê³„ëŠ”?)
3) Interpretation (ì˜ë¯¸/ë§¥ë½/ìƒì§•ì€?)
4) Judgment (ê·¼ê±° ê¸°ë°˜ í‰ê°€)
í•œêµ­ì–´ë¡œ ì§§ê²Œ ë¬¼ì–´ë³´ë©° ëŒ€í™”í•˜ì„¸ìš”.
ì‚¬ìš©ìê°€ ê° ë‹¨ê³„ì— ì„±ì‹¤íˆ ë‹µí•˜ë©´, ë‹¤ìŒ ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë„˜ì–´ê°€ì„¸ìš”.
`;

// ----- RAG ì„¤ì • -----
const DATA_PATH = path.join(process.cwd(), "data/rag/feldman_kr_vectors.json");

// ê°„ë‹¨í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
function cosineSim(a, b) {
  let dot = 0, na = 0, nb = 0;
  for (let i = 0; i < a.length; i++) {
    dot += a[i] * b[i];
    na += a[i] * a[i];
    nb += b[i] * b[i];
  }
  return dot / (Math.sqrt(na) * Math.sqrt(nb));
}

// ì§ˆë¬¸ ê°ì§€ í•¨ìˆ˜
function isQuestion(text) {
  const qTriggers = ["?", "ì–´ë–»ê²Œ", "ì™œ", "ë¬´ì—‡", "ì•Œë ¤ì¤˜", "ë­ì•¼", "ì„¤ëª…"];
  return qTriggers.some((kw) => text.includes(kw));
}

// RAG ë¬¸ì„œ ë¡œë“œ
let DOCS = null;
function loadDocs() {
  if (!DOCS) {
    DOCS = JSON.parse(fs.readFileSync(DATA_PATH, "utf-8"));
  }
  return DOCS;
}

// RAG ê²€ìƒ‰ í•¨ìˆ˜
async function retrieveContext(question) {
  const docs = loadDocs();

  // 1) ì§ˆë¬¸ ì„ë² ë”© ìƒì„±
  const embRes = await openai.embeddings.create({
    model: "text-embedding-3-large",
    input: question,
  });
  const qvec = embRes.data[0].embedding;

  // 2) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ìƒìœ„ 5ê°œ ì„ íƒ
  const top = docs
    .map((d) => ({ ...d, score: cosineSim(qvec, d.vector) }))
    .sort((a, b) => b.score - a.score)
    .slice(0, 5);

  // 3) ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ êµ¬ì„±
  const context = top
    .map((d, i) => `ã€${i + 1}ã€‘${d.title}\n${d.content}`)
    .join("\n\n");

  return context;
}

// ----- ë©”ì¸ POST í•¸ë“¤ëŸ¬ -----
export async function POST(req) {
  try {
    const { messages = [] } = await req.json();
    const lastUserMessage = messages[messages.length - 1]?.content || "";

    let systemMessage = systemPrompt; // ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
    let finalMessages = [];

    // ğŸ¯ ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ê²½ìš° â†’ RAG ê²€ìƒ‰ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ë¡œ êµì²´
    if (isQuestion(lastUserMessage)) {
      const context = await retrieveContext(lastUserMessage);
      systemMessage = `
ë‹¹ì‹ ì€ Feldman ë¯¸ìˆ  ë¹„í‰ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ê´€ë ¨ ì°¸ê³ ìë£Œì…ë‹ˆë‹¤. ì´ë¥¼ ê·¼ê±°ë¡œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µí•˜ì„¸ìš”.
ê°€ëŠ¥í•˜ë©´ ë‹¨ê³„ ê´€ë ¨ ìš©ì–´(ê¸°ìˆ , ë¶„ì„, í•´ì„, íŒë‹¨)ë¥¼ ì–¸ê¸‰í•˜ê³ , ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.

ì§ˆë¬¸: ${lastUserMessage}

ì°¸ê³ ìë£Œ:
${context}
`;
      finalMessages = [{ role: "system", content: systemMessage }];
    } else {
      // ì¼ë°˜ ëŒ€í™” íë¦„ (Feldman ë‹¨ê³„ ì•ˆë‚´)
      finalMessages = [{ role: "system", content: systemPrompt }, ...messages];
    }

    // ğŸ”„ OpenAI Chat Completions (ìŠ¤íŠ¸ë¦¬ë°)
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      stream: true,
      temperature: 0.6,
      messages: finalMessages,
    });

    const encoder = new TextEncoder();

    const stream = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of completion) {
            const delta = chunk?.choices?.[0]?.delta?.content || "";
            if (delta) controller.enqueue(encoder.encode(delta));
          }
        } catch (err) {
          controller.error(err);
        } finally {
          controller.close();
        }
      },
    });

    return new Response(stream, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-cache",
      },
    });
  } catch (e) {
    return new Response(`Error: ${e.message}`, { status: 500 });
  }
}
